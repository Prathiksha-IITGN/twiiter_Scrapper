# -*- coding: utf-8 -*-
"""Twitter_Scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1--vHLeu4nM1Cx-ZJfV6uVqUv2SMUUqjR
"""

#pip install pymongo

import pymongo
from pymongo import MongoClient

#!pip install streamlit
import streamlit as st

# Connect to MongoDB
try:
  client = MongoClient('mongodb://localhost:27017')
  db = client.twitter_data
  collection = db.scraped_data
  st.success("Successfully connected to MongoDB")
except Exception as e:
  st.error("Error connecting to MongoDB: {}".format(e))
  collection=None

# try:
#     client = pymongo.MongoClient("mongodb://<host>:<port>/")
#     db = client["<database_name>"]
#     collection = db["<collection_name>"]
#     st.success("Successfully connected to MongoDB")
# except Exception as e:
#     st.error("Error connecting to MongoDB: {}".format(e))
#     collection = None

# try:
#     client = pymongo.MongoClient("mongodb://<host>:<port>/")
#     db = client["<database_name>"]
#     collection = db["<collection_name>"]
#     st.success("Successfully connected to MongoDB")
# except Exception as e:
#     st.error("Error connecting to MongoDB: {}".format(e))
#     collection = None





#!pip install snscrape

# import snscrape.modules.twitter as sntwitter
# import pandas as pd
# import datetime

# # Create a function to scrape Twitter data
# def scrape_twitter_data(hashtag, start_date, end_date, tweet_count):
#     tweets_list = []
#     for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#'+hashtag+' since:'+start_date+' until:'+end_date).get_items()):
#         if i>tweet_count:
#             break
#         tweets_list.append([tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.url, tweet.source  ])
#     return tweets_list

# st.title("Twitter Scraper")

# Create a form to enter the hashtag, date range, and tweet count
# hashtag = st.text_input("Enter Hashtag or keyword: ")
# start_date = st.date_input("Enter start date (YYYY-MM-DD): ")
# end_date = st.date_input("Enter end date (YYYY-MM-DD): ")
# tweet_count = st.number_input("Enter number of tweets to scrape: ")

# # Create a button to scrape the data
# tweets=0
# if st.button("Scrape Data"):
#     tweets_list = scrape_twitter_data(hashtag, start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d"), tweet_count)
#     tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username','url','source'])
#     tweets=tweets_df.to_dict()
#     st.dataframe(tweets_df)
    
#     # if st.button("Upload Data to Database"):
#     #     doc = {
#     #         'hashtag': hashtag,
#     #         'timestamp': datetime.datetime.now(),
#     #         'data': tweets
#     #     }
#     #     result = collection.insert_many(doc)
#     #     if result.acknowledged:
#     #       st.success("Data uploaded to Database!")
#     #     else:
#     #       st.error("Data not uploaded to Database")

        
#     # if st.button("Download Data to CSV"):
#     #     st.set_option('deprecation.showfileUploaderEncoding', False)
#     #     st.set_option('deprecation.showfileUploader', False)
#     #     st.set_option('download.file_name', 'tweets.csv')
#     #     st.set_option('download.file_path', 'tweets.csv')
#     #     st.write("Please wait while the data is downloading...")
#     #     st.dataframe(tweets_df)
#     #     st.write("Data is ready to download")
#     #     st.file_downloader("Download tweets.csv", 'tweets.csv')
#     # if st.button("Download Data to json"):
#     #     st.set_option('deprecation.showfileUploaderEncoding', False)
#     #     st.set_option('deprecation.showfileUploader', False)
#     #     st.set_option('download.file_name', 'tweets.json')
#     #     st.set_option('download.file_path', 'tweets.json')
#     #     st.write("Please wait while the data is downloading...")
#     #     st.dataframe(tweets_df)
#     #     st.write("Data is ready to download")
#     #     st.file_downloader("Download tweets.json", 'tweets.json')

# # Create a radio button group for the download options
# download_options = st.radio("Select download option:", ("Database", "CSV", "JSON"))

# # Check the selected option and perform the corresponding action
# if download_options == "Database":
#     if st.button("Upload Data to Database"):
#       doc = {
#              'hashtag': hashtag,
#             'timestamp': datetime.datetime.now(),
#              'data': tweets
#       }
#       result = collection.insert_many(doc)
#       if result.acknowledged:
#         st.success("Data uploaded to Database!")
#       else:
#         st.error("Data not uploaded to Database")
#         # Code to upload data to database
# elif download_options == "CSV":
#   if st.button("Download Data to CSV"):
#     st.set_option('deprecation.showfileUploaderEncoding', False)
#     st.set_option('deprecation.showfileUploader', False)
#     st.set_option('download.file_name', 'tweets.csv')
#     st.set_option('download.file_path', 'tweets.csv')
#     st.write("Please wait while the data is downloading...")
#     st.dataframe(tweets_df)
#     st.write("Data is ready to download")
#     st.file_downloader("Download tweets.csv", 'tweets.csv')
#         # Code to download data as CSV
# elif download_options == "JSON":
#   if st.button("Download Data to json"):
#     st.set_option('deprecation.showfileUploaderEncoding', False)
#     st.set_option('deprecation.showfileUploader', False)
#     st.set_option('download.file_name', 'tweets.json')
#     st.set_option('download.file_path', 'tweets.json')
#     st.write("Please wait while the data is downloading...")
#     st.dataframe(tweets_df)
#     st.write("Data is ready to download")
#     st.file_downloader("Download tweets.json", 'tweets.json')
#         # Code to download data as JSON

# import pymongo

# # Connect to MongoDB
# try:
#     client = pymongo.MongoClient("mongodb://<host>:<port>/")
#     db = client["<database_name>"]
#     collection = db["<collection_name>"]
#     st.success("Successfully connected to MongoDB")
# except Exception as e:
#     st.error("Error connecting to MongoDB: {}".format(e))
#     collection = None
import snscrape.modules.twitter as sntwitter
import pandas as pd
import datetime

# Create a function to scrape Twitter data
def scrape_twitter_data(hashtag, start_date, end_date, tweet_count):
    tweets_list = []
    for i,tweet in enumerate(sntwitter.TwitterSearchScraper('#'+hashtag+' since:'+start_date+' until:'+end_date).get_items()):
        if i>tweet_count:
            break
        tweets_list.append([tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.url, tweet.source  ])
    return tweets_list

st.title("Twitter Scraper")

# Create a form to enter the hashtag, date range, and tweet count
hashtag = st.text_input("Enter Hashtag or keyword: ")
start_date = st.date_input("Enter start date (YYYY-MM-DD): ")
end_date = st.date_input("Enter end date (YYYY-MM-DD): ")
tweet_count = st.number_input("Enter number of tweets to scrape: ")


# Create a button to scrape the data
tweets=0
if st.button("Scrape Data"):
    tweets_list = scrape_twitter_data(hashtag, start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d"), tweet_count)
    tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username','url','source'])
    tweets=tweets_df.to_dict()
    st.dataframe(tweets_df)
    # Create a radio button group for the download options
    
tweets_list = scrape_twitter_data(hashtag, start_date.strftime("%Y-%m-%d"), end_date.strftime("%Y-%m-%d"), tweet_count)   
tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username','url','source'])
download_options = st.radio("Select download option:", ("Database", "CSV", "JSON"))
if download_options == "Database":
  if collection is not None:
    if st.button("Upload Data to Database"):
      try:
        doc = {'hashtag': hashtag,
                'timestamp': datetime.datetime.now(),
                'data': tweets_df
        }
        result = collection.insert_one(doc)
        if result.acknowledged:
          st.success("Data uploaded to MongoDB!")
        else:
          st.error("Data not uploaded to MongoDB")
      except Exception as e:
              st.error("Error uploading data to MongoDB: {}".format(e))
  else:
    st.error("Please check your MongoDB connection")
elif download_options == "CSV":
  if st.button("Download Data to CSV"):
    tweets_df.to_csv('tweets.csv', index=False)
    st.write("Please wait while the data is downloading...")
    st.dataframe(tweets_df)
    st.write("Data is ready to download")
    st.markdown('<a href="./tweets.csv" download>Download CSV</a>', unsafe_allow_html=True)

elif download_options == "JSON":
  if st.button("Download Data to json"):
    st.set_option('deprecation.showfileUploaderEncoding', False)
    #st.set_option('deprecation.showfileUploader', False)
    # st.set_option('download.file_name', 'tweets.json')
    # st.set_option('download.file_path', 'tweets.json')
    st.write("Please wait while the data is downloading...")
    st.dataframe(tweets_df)
    st.write("Data is ready to download")
    st.file_downloader("Download tweets.json", 'tweets.json')









